{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61c00ebe2ffbf464aa183a15c05dcba67a2258e0"
   },
   "source": [
    "<h1><center><font size=\"6\">Breast Cancer Diagnosis Prediction using H2O</font></center></h1>\n",
    "\n",
    "\n",
    "<img src=\"https://kaggle2.blob.core.windows.net/datasets-images/180/384/3da2510581f9d3b902307ff8d06fe327/dataset-card.jpg\" width=\"400\"></img>\n",
    "\n",
    "\n",
    "# <a id='0'>Content</a>\n",
    "\n",
    "- <a href='#1'>Introduction</a>  \n",
    "- <a href='#2'>Load packages</a>  \n",
    "- <a href='#3'>Read the data</a>  \n",
    "- <a href='#4'>Check the data</a>  \n",
    "- <a href='#5'>Data exploration</a>\n",
    "- <a href='#6'>Predictive model</a>  \n",
    "    - <a href='#61'>Split the data</a> \n",
    "    - <a href='#62'>Train  GBM</a>   \n",
    "    - <a href='#63'>Model evaluation</a>  \n",
    "    - <a href='#64'>Prediction</a>     \n",
    "- <a href='#8'>References</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# <a id=\"1\">Introduction</a>  \n",
    "\n",
    "## The dataset\n",
    "\n",
    "The **Breast Cancer (Wisconsin) Diagnosis dataset** <a href='#8'>[1]</a> contains the diagnosis and a set of 30  features describing the characteristics of the cell nuclei present in the digitized image of a of a fine needle aspirate (FNA) of a breast mass.\n",
    "Ten real-valued features are computed for each cell nucleus:  \n",
    "+ **radius** (mean of distances from center to points on the perimeter);  \n",
    "+ **texture** (standard deviation of gray-scale values);  \n",
    "+ **perimeter**;  \n",
    "+ **area**;  \n",
    "+ **smoothness** (local variation in radius lengths);  \n",
    "+ **compactness** (perimeter^2 / area - 1.0);  \n",
    "+ **concavity** (severity of concave portions of the contour);  \n",
    "+ **concave points** (number of concave portions of the contour);  \n",
    "+ **symmetry**;  \n",
    "+ **fractal dimension** (\"coastline approximation\" - 1).\n",
    "\n",
    "The **mean**, standard error (**SE**) and \"**worst**\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features.\n",
    "\n",
    "\n",
    "## H2O  \n",
    "\n",
    "H2O is a Java-based software for data modeling and general computing. Primary purpose of H2O is as a distributed (many machines), parallel (many CPUs), in memory (several hundred GBs Xmx) processing engine. It has both Python and R interfaces <a href='#8'>[2]</a>.  \n",
    "\n",
    "## Analysis\n",
    "\n",
    "We will analyze the features to understand the predictive value for diagnosis. We will then create models using two different algorithms and use the models to predict the diagnosis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85eb83bcccbd9326bf36867ed464c9ac59069854"
   },
   "source": [
    "# <a id=\"2\">Load packages</a>  \n",
    "\n",
    "We load the packages we will use in the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90f83289cff505cab631c41717df214755c12edc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import itertools\n",
    "import h2o\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0550fb1178e729f79f31dc542e91412c82d2ce4e"
   },
   "source": [
    "# <a id=\"3\">Read the data</a>  \n",
    "\n",
    "For reading the data, we will use also H2O. First, we will initialize H2O.\n",
    "\n",
    "## Initialize H2O\n",
    "\n",
    "H2O will first try to connect to an existing instance. If none available, will start one. Then informations about this engine are printed.  At the end connection to the H2O server is attempted and reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d71c786f9f42a802be5ba28111c41b0a17b6c579"
   },
   "outputs": [],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7de7a67e5492e25d0ab12ecd6e76807f85661f6"
   },
   "source": [
    "More information are presented: the H2O cluster uptime, timezone, version, version age, cluster name, hardware resources allocated ( number of nodes, memory, cores), the connection url, H2O API extensions exposed and the Python version used.\n",
    "\n",
    "## Import the data\n",
    "\n",
    "We already initialized the H2O engine, now we will use H2O to import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c294d57584aaf11a6eed3ec0050c30ed8d0ee5f6"
   },
   "outputs": [],
   "source": [
    "data_df = h2o.import_file(\"../input/data.csv\", destination_frame=\"data_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "933699c6e63776c0ea4708d158ac879b72dd9637"
   },
   "source": [
    "# <a id=\"4\">Check the data</a>  \n",
    "\n",
    "\n",
    "We use also H2O function **describe** to check the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e0ac0c525f0e0647b0b643e2ba858c447a25451"
   },
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bdb36317e3cfea13d70c93c7506ded01f2ab2f3"
   },
   "source": [
    "There are 569 rows and 33 columns in the data. For each column, the following informations are shown:  \n",
    "\n",
    "+ type;  \n",
    "+ min;  \n",
    "+ mean;  \n",
    "+ max;  \n",
    "+ standard deviation (sigma);  \n",
    "+ number of zeros (zero);  \n",
    "+ number of missing values (missing);  \n",
    "+ a certain number of selected values (first 10);  \n",
    "\n",
    "Notes: Calling **describe()** function this way is equivalent with calling **summary()**.   \n",
    "We can call describe with a parameter different from 0. In this case, more information about the type of chunk compression data and frame distribution, besides the data description, is given.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f8f551dd0d8a1c13707a163effd869aaa657272"
   },
   "outputs": [],
   "source": [
    "data_df.describe(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b05bad079311bf845b526deb1c157d91f5829eed"
   },
   "source": [
    "# <a id=\"5\">Explore the data</a>  \n",
    "\n",
    "We will use another functions from H2O to explore the data.\n",
    "\n",
    "Let's start by showing the distribution of features, grouped by **diagnosis**, which is the **target** value.\n",
    "\n",
    "We start by looking how many cases are with **diagnosis** of each type (malignant (M) or benign (B))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e2d1fe5393798d9582863f58db02f9ce35d1ffe"
   },
   "outputs": [],
   "source": [
    "df_group=data_df.group_by(\"diagnosis\").count()\n",
    "df_group.get_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e107a7021974971135ce9997a1c2ecd80cc8bfe6"
   },
   "outputs": [],
   "source": [
    "features = [f for f in data_df.columns if f not in ['id', 'diagnosis', 'C33']]\n",
    "\n",
    "i = 0\n",
    "t0 = data_df[data_df['diagnosis'] == 'M'].as_data_frame()\n",
    "t1 = data_df[data_df['diagnosis'] == 'B'].as_data_frame()\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(6,5,figsize=(16,24))\n",
    "\n",
    "for feature in features:\n",
    "    i += 1\n",
    "    plt.subplot(6,5,i)\n",
    "    sns.kdeplot(t0[feature], bw=0.5,label=\"Malignant\")\n",
    "    sns.kdeplot(t1[feature], bw=0.5,label=\"Benign\")\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.show();\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4e4a518019846fb61e104a9a1cee552f033e3ecd"
   },
   "source": [
    "Some of the features show good separation in terms of density plots for the subset with **malignant (M)** diagnosis and the subset with **benign (B)** diagnosis, for example:   \n",
    "\n",
    "* radius_mean;  \n",
    "* texture_mean;  \n",
    "* perimeter_mean;  \n",
    "* area_mean;  \n",
    "* radius_worst;  \n",
    "* texture_worst;  \n",
    "* perimeter_worst;  \n",
    "* area_worst;  \n",
    "Some features show perfect identity of the density plots grouped by diagnosis, as following:  \n",
    "* compactness_se;  \n",
    "* concavity_se;  \n",
    "* concave_points_se;  \n",
    "* simmetry_se;  \n",
    "* smoothness_se;  \n",
    "\n",
    "Let's represent the correlation between the features, excluding id, C33 and diagnosis:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1983049fef42c3694941ed296d58c459727a9b2d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "corr = data_df[features].cor().as_data_frame()\n",
    "corr.index = features\n",
    "sns.heatmap(corr, annot = True, cmap='YlGnBu', linecolor=\"white\", vmin=-1, vmax=1, cbar_kws={\"orientation\": \"horizontal\"})\n",
    "plt.title(\"Correlation Heatmap for the features (excluding id, C33 & diagnosis)\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbcce41db32e25e68bbc88f9e8228f24576dbf90"
   },
   "source": [
    "Some of the features are strongly correlated , as following:  \n",
    "\n",
    "* radius_mean with perimeter_mean;  \n",
    "* radius_mean with texture_mean;  \n",
    "* perimeter_worst with radius_worst;  \n",
    "* perimeter_worst with area_worst;  \n",
    "* area_se with perimeter_se;  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c397751180464debab5695febca44ed41d8417f"
   },
   "source": [
    "# <a id=\"6\">Predictive model</a>   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ea275178209e4a11b58dc2cea7c4b7d7d3260a95"
   },
   "source": [
    "# <a id=\"61\">Split the data</a> \n",
    "\n",
    "Let's start by spliting the data in train, validation and test sets. We will use 60%, 20% and 20% splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a595168120f802b26026c07bec461125bfad05f3"
   },
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df = data_df.split_frame(ratios=[0.6,0.2], seed=2018)\n",
    "target = \"diagnosis\"\n",
    "train_df[target] = train_df[target].asfactor()\n",
    "valid_df[target] = valid_df[target].asfactor()\n",
    "test_df[target] = test_df[target].asfactor()\n",
    "print(\"Number of rows in train, valid and test set : \", train_df.shape[0], valid_df.shape[0], test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53b173fadc244c715da38fc81b07c081abc1a7c2"
   },
   "source": [
    "## <a id=\"62\">Train  GBM</a> \n",
    "\n",
    "We will use a GBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fca680a25d4a085f00241f1d7a22237d1bdcfb8d"
   },
   "outputs": [],
   "source": [
    "# define the predictor list - it will be the same as the features analyzed previously\n",
    "predictors = features\n",
    "# initialize the H2O GBM \n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "# train with the initialized model\n",
    "gbm.train(x=predictors, y=target, training_frame=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9486fd66f0996f8d794a917414609f217380efa3"
   },
   "source": [
    "\n",
    "## <a id=\"63\">Model evaluation</a> \n",
    "\n",
    "\n",
    "Let's inspect the model already trained. We can print the summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5dc823f6550d7273274dc4593a4c8935cfd6142"
   },
   "outputs": [],
   "source": [
    "gbm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40540ba1f7172a3352926286316d5f9ebdc51ecb"
   },
   "source": [
    "This shows that we used 50 trees, 50 internal trees. It is also showing the min and max tree depth (4,5), the min and max number of leaves (7,14) and the mean values for tree depth and number of leaves.\n",
    "\n",
    "We can also inspect the model further, looking to other informations.\n",
    "\n",
    "Let's see the model performance for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eea851f41bd065a3f5a2187eefa5e6c1b9eeb9f8"
   },
   "outputs": [],
   "source": [
    "print(gbm.model_performance(valid_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "afeb7552636b0e791ade027fb764396f03299021"
   },
   "source": [
    "We can see that the AUC is 0.9987 for validation set and Gini coeff is 0.997. LogLoss is 0.05.\n",
    "\n",
    "Confusion matrix show that only one value in the validation set was wrongly predicted.  \n",
    "\n",
    "With such good results in the validation set, we will not need to further tune the model.  We can now try and predict the test set values.\n",
    "\n",
    "Let's also show the variable importance plot for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a33abd54f15c957ba5e4b9b24bc169da8d8b7f4e"
   },
   "outputs": [],
   "source": [
    "gbm.varimp_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1106aa1ccb3de4fbbe727bc77d33f5da90ab1ba5"
   },
   "source": [
    "The most important features are perimeter_worst, concave_points_mean, radius_worst, concave_points_worst.\n",
    "\n",
    "Let's now use the model for prediction.\n",
    "\n",
    "## <a id=\"64\">Predict</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe5aded8cebb37860617f8929934b29be0075697"
   },
   "outputs": [],
   "source": [
    "pred_val = list(gbm.predict(test_df[predictors])[0])\n",
    "true_val = list(test_df[target])\n",
    "prediction_acc = np.mean(pred_val == true_val)\n",
    "print(\"Prediction accuracy: \", prediction_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "162af3b4869d8605a082a4f8fa5273a8adfdc6d7"
   },
   "source": [
    "The accuracy is 1 (100% correctly predicted values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f800da317c319947233d92f28827fe0b9ffb7f04"
   },
   "source": [
    "# <a id=\"8\">References</a>\n",
    "\n",
    "[1] Breast Cancer Wisconsin (Diagnostic) Data Set, https://www.kaggle.com/uciml/breast-cancer-wisconsin-data  \n",
    "[2] SRK, Getting started with H2O,  https://www.kaggle.com/sudalairajkumar/getting-started-with-h2o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
